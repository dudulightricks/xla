{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "# Copyright 2024 Google LLC.\n",
        "# SPDX-License-Identifier: Apache-2.0"
      ],
      "metadata": {
        "id": "1XYgcZGSUZ4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchdata torchtext torch_xla libtpu-nightly -y\n",
        "\n",
        "!pip3 install --pre torch torchvision torchtext --index-url https://download.pytorch.org/whl/nightly/cpu\n",
        "!pip3 install https://storage.googleapis.com/pytorch-xla-releases/wheels/tpuvm/torch_xla-nightly-cp310-cp310-linux_x86_64.whl\n",
        "!pip install torch_xla[tpu] -f https://storage.googleapis.com/libtpu-releases/index.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQSB7UguZzVQ",
        "outputId": "be36d9a1-eff1-4e1a-d085-e11b9ef79f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.5.0.dev20240629+cpu\n",
            "Uninstalling torch-2.5.0.dev20240629+cpu:\n",
            "  Successfully uninstalled torch-2.5.0.dev20240629+cpu\n",
            "Found existing installation: torchvision 0.20.0.dev20240629+cpu\n",
            "Uninstalling torchvision-0.20.0.dev20240629+cpu:\n",
            "  Successfully uninstalled torchvision-0.20.0.dev20240629+cpu\n",
            "Found existing installation: torchdata 0.7.1a0+b0e25e2\n",
            "Uninstalling torchdata-0.7.1a0+b0e25e2:\n",
            "  Successfully uninstalled torchdata-0.7.1a0+b0e25e2\n",
            "Found existing installation: torchtext 0.17.0.dev20240629+cpu\n",
            "Uninstalling torchtext-0.17.0.dev20240629+cpu:\n",
            "  Successfully uninstalled torchtext-0.17.0.dev20240629+cpu\n",
            "Found existing installation: torch-xla 2.4.0+git3bdca4d\n",
            "Uninstalling torch-xla-2.4.0+git3bdca4d:\n",
            "  Successfully uninstalled torch-xla-2.4.0+git3bdca4d\n",
            "Found existing installation: libtpu-nightly 0.1.dev20240618+default\n",
            "Uninstalling libtpu-nightly-0.1.dev20240618+default:\n",
            "  Successfully uninstalled libtpu-nightly-0.1.dev20240618+default\n",
            "Looking in indexes: https://download.pytorch.org/whl/nightly/cpu\n",
            "Collecting torch\n",
            "  Using cached https://download.pytorch.org/whl/nightly/cpu/torch-2.5.0.dev20240630%2Bcpu-cp310-cp310-linux_x86_64.whl (195.5 MB)\n",
            "Collecting torchvision\n",
            "  Using cached https://download.pytorch.org/whl/nightly/cpu/torchvision-0.20.0.dev20240629%2Bcpu-cp310-cp310-linux_x86_64.whl (1.8 MB)\n",
            "Collecting torchtext\n",
            "  Using cached https://download.pytorch.org/whl/nightly/cpu/torchtext-0.17.0.dev20240630%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Collecting torch\n",
            "  Using cached https://download.pytorch.org/whl/nightly/cpu/torch-2.5.0.dev20240629%2Bcpu-cp310-cp310-linux_x86_64.whl (195.5 MB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "INFO: pip is looking at multiple versions of torchtext to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchtext\n",
            "  Using cached https://download.pytorch.org/whl/nightly/cpu/torchtext-0.17.0.dev20240629%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: torch, torchvision, torchtext\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.15 requires torch<2.4,>=1.10, but you have torch 2.5.0.dev20240629+cpu which is incompatible.\n",
            "torchaudio 2.3.0+cpu requires torch==2.3.0, but you have torch 2.5.0.dev20240629+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.5.0.dev20240629+cpu torchtext-0.17.0.dev20240629+cpu torchvision-0.20.0.dev20240629+cpu\n",
            "Collecting torch-xla==nightly\n",
            "  Using cached https://storage.googleapis.com/pytorch-xla-releases/wheels/tpuvm/torch_xla-nightly-cp310-cp310-linux_x86_64.whl (83.4 MB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torch-xla==nightly) (1.4.0)\n",
            "Requirement already satisfied: cloud-tpu-client>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from torch-xla==nightly) (0.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from torch-xla==nightly) (6.0.1)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.10/dist-packages (from cloud-tpu-client>=0.10.0->torch-xla==nightly) (1.8.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from cloud-tpu-client>=0.10.0->torch-xla==nightly) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (0.22.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (0.2.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (1.34.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (1.16.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (3.0.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla==nightly) (0.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla==nightly) (0.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla==nightly) (4.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (1.63.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (5.3.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (2024.6.2)\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-2.4.0+git3bdca4d\n",
            "Looking in links: https://storage.googleapis.com/libtpu-releases/index.html\n",
            "Requirement already satisfied: torch_xla[tpu] in /usr/local/lib/python3.10/dist-packages (2.4.0+git3bdca4d)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torch_xla[tpu]) (1.4.0)\n",
            "Requirement already satisfied: cloud-tpu-client>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from torch_xla[tpu]) (0.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from torch_xla[tpu]) (6.0.1)\n",
            "Collecting libtpu-nightly==0.1.dev20240618 (from torch_xla[tpu])\n",
            "  Using cached https://storage.googleapis.com/libtpu-default-releases/wheels/libtpu-nightly/libtpu_nightly-0.1.dev20240618%2Bdefault-py3-none-any.whl (116.9 MB)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.10/dist-packages (from cloud-tpu-client>=0.10.0->torch_xla[tpu]) (1.8.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from cloud-tpu-client>=0.10.0->torch_xla[tpu]) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (0.22.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (0.2.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (1.34.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (1.16.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (3.0.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (0.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (0.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (4.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (1.63.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (5.3.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla[tpu]) (2024.6.2)\n",
            "Installing collected packages: libtpu-nightly\n",
            "Successfully installed libtpu-nightly-0.1.dev20240618+default\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pytorch/data.git torchdata\n",
        "%cd torchdata/\n",
        "!git reset --hard b0e25e2\n",
        "!pip install .\n",
        "!cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfJi9wMZaE1k",
        "outputId": "e8ab14fe-b553-4cfe-82fd-186675c15fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'torchdata' already exists and is not an empty directory.\n",
            "/content/torchdata\n",
            "HEAD is now at b0e25e26 Save state in dataset_iter_state when dataset is also an iterator (#1279)\n",
            "Processing /content/torchdata\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.1a0+b0e25e2) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.1a0+b0e25e2) (2.31.0)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.1a0+b0e25e2) (2.5.0.dev20240629+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata==0.7.1a0+b0e25e2) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata==0.7.1a0+b0e25e2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata==0.7.1a0+b0e25e2) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata==0.7.1a0+b0e25e2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata==0.7.1a0+b0e25e2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata==0.7.1a0+b0e25e2) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.7.1a0+b0e25e2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.7.1a0+b0e25e2) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.7.1a0+b0e25e2) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata==0.7.1a0+b0e25e2) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata==0.7.1a0+b0e25e2) (1.3.0)\n",
            "Building wheels for collected packages: torchdata\n",
            "  Building wheel for torchdata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchdata: filename=torchdata-0.7.1a0+b0e25e2-py3-none-any.whl size=209379 sha256=6efdf9546495e5571448faf2f413c5455cfa654edb0ac7d0ed114aff07fccf08\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gzox3g1f/wheels/ec/25/35/f221f33eac65247616ab85a393ae829e700717149ec6f4d1ef\n",
            "Successfully built torchdata\n",
            "Installing collected packages: torchdata\n",
            "Successfully installed torchdata-0.7.1a0+b0e25e2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 list | grep 'torch'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNpl-XrTa72H",
        "outputId": "453f0bfe-3ffd-4844-e400-2ed7bc49cbf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch                        2.5.0.dev20240629+cpu\n",
            "torch-xla                    2.4.0+git3bdca4d\n",
            "torchaudio                   2.3.0+cpu\n",
            "torchdata                    0.7.1a0+b0e25e2\n",
            "torchtext                    0.17.0.dev20240629+cpu\n",
            "torchvision                  0.20.0.dev20240629+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install panda\n",
        "!pip install pandas\n",
        "!pip install 'portalocker>=2.0.0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAwoAt9JaNQT",
        "outputId": "cc307081-5512-4e1e-a20b-22a866e9439f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: panda in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from panda) (67.7.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from panda) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->panda) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->panda) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->panda) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->panda) (2024.6.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.10/dist-packages (2.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77ML-zSJo-iE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8d7832-b6df-42cd-dcbd-d14d8352a154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.0.dev20240629+cpu\n",
            "0.17.0.dev20240629+cpu\n",
            "2.4.0+git3bdca4d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/datasets/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "import torch_xla\n",
        "from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import torch_xla.core.xla_model as xm\n",
        "from torchtext.datasets import AG_NEWS\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchtext.__version__)\n",
        "print(torch_xla.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchdata\n",
        "data_dir = './data' # TODO\n",
        "dataset, test_data = AG_NEWS(root=data_dir)"
      ],
      "metadata": {
        "id": "IRCOpnjqpIzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef503bd3-82e4-4d38-8298-795678bc8095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/torchdata/torchdata/datapipes/__init__.py:18: UserWarning: \n",
            "################################################################################\n",
            "WARNING!\n",
            "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
            "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
            "to learn more and leave feedback.\n",
            "################################################################################\n",
            "\n",
            "  deprecation_warning()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(dataset))\n",
        "next(iter(test_data))"
      ],
      "metadata": {
        "id": "Vg34gNj_pLgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97018f14-f6af-4a17-d0fd-1ae9aa46d290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "tokenizer('I love BITAmin!')"
      ],
      "metadata": {
        "id": "4t1-gOVTpNJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd6b4bf-7a8d-4ff8-f02e-328814bd3413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'love', 'bitamin', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_tokens(data):\n",
        "  for _, text in data:\n",
        "    yield tokenizer(text)"
      ],
      "metadata": {
        "id": "5bQ4c_dlpPGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_vocab_from_iterator(yield_tokens(dataset), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "j9Sw-N6epQz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b22eb4-e3eb-44fb-ba23-eb8d5e0994c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:365: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocess(x):\n",
        "  return vocab(tokenizer(x))"
      ],
      "metadata": {
        "id": "cvpHPW3wpSnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_preprocess(x):\n",
        "  return int(x) - 1"
      ],
      "metadata": {
        "id": "YKTcMh5PpUO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torchtext.datasets.AG_NEWS(root=data_dir, split='test')"
      ],
      "metadata": {
        "id": "e7b2FfaypVhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_AG_NEWS_PATH = 'data/datasets/AG_NEWS/train.csv' # TODO\n",
        "TEST_AG_NEWS_PATH = 'data/datasets/AG_NEWS/test.csv'# TODO"
      ],
      "metadata": {
        "id": "Tse13RrnpW6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, path: str ='./data/AG_NEWS/train.csv', train=True):\n",
        "        tqdm_notebook.pandas(desc=\"PROGRESS>>\")\n",
        "        self.data = pd.read_csv(path, sep=',', header=None, names=['class','title','description'])\n",
        "        self.train = train\n",
        "        self.path = path\n",
        "\n",
        "        data = self.data['title'] + ' ' + self.data['description']\n",
        "        self.X = list()\n",
        "        for line in data:\n",
        "          self.X.append(line)\n",
        "        self.y = self.data['class']\n",
        "\n",
        "        self.classes = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
        "\n",
        "    def __len__(self):\n",
        "        len_dataset = None\n",
        "        len_dataset = len(self.X)\n",
        "        return len_dataset\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X,y = None, None\n",
        "        X = self.X[idx]\n",
        "        if self.train is True:\n",
        "            y = self.y[idx]\n",
        "        return y, X\n",
        "\n",
        "    def split_dataset(self, val_ratio = 0.2):\n",
        "        data_size = len(self)\n",
        "        val_set_size = int(data_size * val_ratio)\n",
        "        train_set_size = data_size - val_set_size\n",
        "\n",
        "        train_set, val_set = random_split(self, [train_set_size, val_set_size])\n",
        "\n",
        "        return train_set, val_set"
      ],
      "metadata": {
        "id": "U1XUyxJ4pYHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(TRAIN_AG_NEWS_PATH, train=True)\n",
        "train_dataset, val_dataset = dataset.split_dataset(0.2)"
      ],
      "metadata": {
        "id": "2vCptGpzpajg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dataset))"
      ],
      "metadata": {
        "id": "8chkEbbjpbw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff13048-1237-42b5-f4a1-8d117c2a5ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,\n",
              " 'Myskina beats Dementieva to win in Moscow In a rematch of All-Russian French Open championship match, Anastasia Myskina trounced Elena Dementieva 7-5 and 6-0 to win the Kremlin Cup final to retain her Moscow title on Sunday.')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(val_dataset))"
      ],
      "metadata": {
        "id": "lHI127HUpc6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b45cc86-e95d-49e1-db9e-ce63902fcfcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,\n",
              " 'Henman fires amid models furore Tim Henman, in common with Michael Owen, has found the target here at last. The British No 1, beaten in his opening matches on two previous visits to the Madrid Masters, defeated Albert Costa, of Spain, yesterday, 6-4, 6-2.')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset), len(val_dataset)"
      ],
      "metadata": {
        "id": "CJGa672hpeyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d10c27c4-78be-4b12-ccc2-1ca1373a66c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96000, 24000)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_preprocess(train_dataset[0][1])"
      ],
      "metadata": {
        "id": "6eK0xLPVpgGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a62e6e-5ec1-4013-a82e-e0285890817e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6016,\n",
              " 1808,\n",
              " 5798,\n",
              " 4,\n",
              " 109,\n",
              " 7,\n",
              " 930,\n",
              " 7,\n",
              " 5,\n",
              " 7585,\n",
              " 6,\n",
              " 11100,\n",
              " 432,\n",
              " 149,\n",
              " 417,\n",
              " 620,\n",
              " 3,\n",
              " 8250,\n",
              " 6016,\n",
              " 14217,\n",
              " 5386,\n",
              " 5798,\n",
              " 3878,\n",
              " 8,\n",
              " 4612,\n",
              " 4,\n",
              " 109,\n",
              " 2,\n",
              " 3590,\n",
              " 174,\n",
              " 216,\n",
              " 4,\n",
              " 4174,\n",
              " 256,\n",
              " 930,\n",
              " 391,\n",
              " 10,\n",
              " 91,\n",
              " 1]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = xm.xla_device()\n",
        "print(xm.xrt_world_size())\n",
        "device"
      ],
      "metadata": {
        "id": "R-rCj7rfphSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ca368c-c87d-4b61-c3ff-941e7351eaea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    labels, texts, offsets = [], [], [0]\n",
        "    for (label, text) in batch:\n",
        "        labels.append(label_preprocess(label))\n",
        "        processed_text = torch.tensor(text_preprocess(text), dtype=torch.int64)\n",
        "        texts.append(processed_text)\n",
        "        offsets.append(processed_text.size(0))\n",
        "\n",
        "    labels = torch.tensor(labels, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    texts = torch.cat(texts)\n",
        "    return labels.to(device), texts.to(device), offsets.to(device)\n",
        "\n",
        "train_sampler = torch.utils.data.RandomSampler(train_dataset)\n",
        "test_sampler = torch.utils.data.RandomSampler(val_dataset)"
      ],
      "metadata": {
        "id": "igK2e8oDpjKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128"
      ],
      "metadata": {
        "id": "tn1_Do4fplQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, num_classes):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.embedding = nn.EmbeddingBag(self.vocab_size, self.embed_dim, sparse=False)\n",
        "\n",
        "        self.rnn = nn.GRU(self.embed_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(self.hidden_dim, self.num_classes)\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "\n",
        "        embedded = self.embedding(text, offsets).view(batch_size, -1, self.embed_dim)\n",
        "\n",
        "        hidden = torch.zeros(self.num_layers, embedded.size(0), self.hidden_dim).to(device)\n",
        "\n",
        "        rnn_out, hidden= self.rnn(embedded, hidden)\n",
        "        out = self.linear(rnn_out[:, -1:]).view([-1,self.num_classes])\n",
        "        return out"
      ],
      "metadata": {
        "id": "3pOWwHKPpmor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embed_dim = 64\n",
        "hidden_dim = 32\n",
        "num_layers = 1\n",
        "num_classes = 4\n",
        "learning_rate = 0.5\n",
        "epochs = 5\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "log_interval = 100\n",
        "\n",
        "model = TextClassifier(vocab_size, embed_dim, hidden_dim, num_layers, num_classes).to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 2, gamma=0.5)"
      ],
      "metadata": {
        "id": "qPq8FW2VpoXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch, sampler=train_sampler ,drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch, sampler=test_sampler ,drop_last=True)"
      ],
      "metadata": {
        "id": "QzqL6bOlpp4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, epoch):\n",
        "    model.train()\n",
        "    train_acc = 0\n",
        "    train_count = 0\n",
        "    for idx, (labels, texts, offsets) in tqdm(enumerate(dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        labels, texts, offsets = labels.to(device), texts.to(device), offsets.to(device)\n",
        "\n",
        "        outs = model(texts, offsets)\n",
        "        predicts = torch.argmax(outs, dim=-1)\n",
        "\n",
        "        loss = criterion(outs, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_value_(model.parameters(), 5.0) # TODO\n",
        "        #optimizer.step()\n",
        "        xm.optimizer_step(optimizer, barrier=True) # If you use TPU\n",
        "\n",
        "        train_acc += (predicts == labels).sum().item()\n",
        "        train_count += labels.size(0)\n",
        "\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | loss {:8.3f} | accuracy {:8.3f}'.format(epoch, idx, len(dataloader), loss, train_acc / train_count))\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    val_acc = 0\n",
        "    val_count = 0\n",
        "    val_acc_items = []\n",
        "    with torch.no_grad():\n",
        "        for idx, (labels, texts, offsets) in enumerate(dataloader):\n",
        "            labels, texts, offsets = labels.to(device), texts.to(device), offsets.to(device)\n",
        "            outs = model(texts, offsets)\n",
        "            predicts = torch.argmax(outs, dim=-1)\n",
        "            acc_item = (labels == predicts).sum().item()\n",
        "            val_acc_items.append(acc_item)\n",
        "            val_count += labels.size(0)\n",
        "            val_acc = np.sum(val_acc_items) / val_count\n",
        "    return val_acc"
      ],
      "metadata": {
        "id": "j4FRYxn2prdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_acc = 0\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(train_dataloader, epoch)\n",
        "    acc_val = evaluate(val_dataloader)\n",
        "\n",
        "    if total_acc < acc_val:\n",
        "        total_acc = acc_val\n",
        "\n",
        "    print('-' * 60)\n",
        "    print('| end of epoch {:3d} | valid accuracy {:8.3f} '.format(epoch, total_acc))\n",
        "    print('-' * 60)"
      ],
      "metadata": {
        "id": "TfW6yuuPpte-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f61dd7e4-a0da-4335-83a6-5869e5697e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "103it [00:09, 19.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   100/  750 batches | loss    1.341 | accuracy    0.338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "204it [00:15, 17.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   200/  750 batches | loss    1.220 | accuracy    0.393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "304it [00:22, 17.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   300/  750 batches | loss    1.157 | accuracy    0.423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "404it [00:28, 19.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   400/  750 batches | loss    1.166 | accuracy    0.444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "504it [00:33, 20.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/  750 batches | loss    1.034 | accuracy    0.459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "604it [00:39, 18.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   600/  750 batches | loss    1.177 | accuracy    0.472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "704it [00:44, 19.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   700/  750 batches | loss    1.133 | accuracy    0.483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "750it [00:47, 15.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "| end of epoch   1 | valid accuracy    0.561 \n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "104it [00:06, 15.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   2 |   100/  750 batches | loss    1.172 | accuracy    0.578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "203it [00:13, 15.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   2 |   200/  750 batches | loss    0.959 | accuracy    0.581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "304it [00:18, 18.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   2 |   300/  750 batches | loss    1.048 | accuracy    0.587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "403it [00:24, 14.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   2 |   400/  750 batches | loss    0.865 | accuracy    0.591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "503it [00:30, 17.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   2 |   500/  750 batches | loss    0.920 | accuracy    0.597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "603it [00:37, 18.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   2 |   600/  750 batches | loss    1.035 | accuracy    0.602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "704it [00:42, 18.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   2 |   700/  750 batches | loss    0.896 | accuracy    0.607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "750it [00:45, 16.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "| end of epoch   2 | valid accuracy    0.647 \n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105it [00:05, 19.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   3 |   100/  750 batches | loss    0.953 | accuracy    0.652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "204it [00:10, 18.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   3 |   200/  750 batches | loss    0.993 | accuracy    0.653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "304it [00:16, 18.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   3 |   300/  750 batches | loss    0.883 | accuracy    0.655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "404it [00:21, 19.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   3 |   400/  750 batches | loss    0.981 | accuracy    0.656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "503it [00:27, 18.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   3 |   500/  750 batches | loss    0.776 | accuracy    0.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "603it [00:32, 19.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   3 |   600/  750 batches | loss    0.881 | accuracy    0.660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "703it [00:37, 19.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   3 |   700/  750 batches | loss    0.908 | accuracy    0.662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "750it [00:40, 18.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "| end of epoch   3 | valid accuracy    0.676 \n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "104it [00:05, 18.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   4 |   100/  750 batches | loss    0.805 | accuracy    0.671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "204it [00:10, 17.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   4 |   200/  750 batches | loss    0.818 | accuracy    0.676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "304it [00:18, 19.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   4 |   300/  750 batches | loss    0.744 | accuracy    0.679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "403it [00:23, 18.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   4 |   400/  750 batches | loss    0.729 | accuracy    0.681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "504it [00:29, 18.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   4 |   500/  750 batches | loss    0.840 | accuracy    0.684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "604it [00:34, 19.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   4 |   600/  750 batches | loss    0.774 | accuracy    0.685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "704it [00:40, 18.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   4 |   700/  750 batches | loss    0.862 | accuracy    0.687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "750it [00:42, 17.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "| end of epoch   4 | valid accuracy    0.700 \n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "103it [00:06, 18.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   5 |   100/  750 batches | loss    0.787 | accuracy    0.702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "204it [00:11, 18.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   5 |   200/  750 batches | loss    0.700 | accuracy    0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "304it [00:17, 18.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   5 |   300/  750 batches | loss    0.770 | accuracy    0.706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "403it [00:22, 18.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   5 |   400/  750 batches | loss    0.750 | accuracy    0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "503it [00:27, 19.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   5 |   500/  750 batches | loss    0.750 | accuracy    0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "604it [00:34, 17.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   5 |   600/  750 batches | loss    0.733 | accuracy    0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "704it [00:39, 18.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   5 |   700/  750 batches | loss    0.745 | accuracy    0.706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "750it [00:41, 17.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "| end of epoch   5 | valid accuracy    0.709 \n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CustomDataset(TEST_AG_NEWS_PATH, train=False)\n",
        "test_dataloader =  DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch,drop_last=True)"
      ],
      "metadata": {
        "id": "fdK5kpMDpu55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_val = evaluate(test_dataloader)\n",
        "print('-' * 59)\n",
        "print('test accuracy {:8.3f} '.format(acc_val))\n",
        "print('-' * 59)"
      ],
      "metadata": {
        "id": "ENahPkiJpyqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a43487f6-7a64-4f43-8e69-02af661e7b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------\n",
            "test accuracy    0.709 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}